{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqebp8BX_lmO",
        "outputId": "c18100ec-64d2-474c-a9e7-851ab8d8ec18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDpn7hA0vxqh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.models import load_model\n",
        "from multiprocessing import cpu_count\n",
        "from warnings import catch_warnings\n",
        "from warnings import filterwarnings\n",
        "from pandas import read_csv\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas import DataFrame\n",
        "import time\n",
        "#from datetime import datetime\n",
        "import datetime\n",
        "import itertools\n",
        "import mysql.connector\n",
        "from mysql.connector import connection\n",
        "from mysql.connector import errorcode\n",
        "from statistics import mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUj-dJTOwa2l"
      },
      "outputs": [],
      "source": [
        "station = ['t51']\n",
        "previous_id = np.zeros(len(station))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFH57JZowa5J"
      },
      "outputs": [],
      "source": [
        "def loadData(t):\n",
        "    myconn = mysql.connector.connect(host = \"82.180.142.51\",\n",
        "                                database = \"u978805288_land\",\n",
        "                                user = \"u978805288_root\",\n",
        "                                password= \"ACSL@b123\")\n",
        "    (myconn)\n",
        "\n",
        "    sql_select_query = \"select sensor_id, value from data_log, info_time where data_log.info_id = info_time.info_id AND data_log.triplet_id = '\"+t+\"' ORDER BY data_log.info_id desc limit 60\"\n",
        "    date_select_query = \"select Date_Time from info_time where triplet_id='\"+t+\"' order by info_id desc limit 1\"\n",
        "\n",
        "    cursor = myconn.cursor()\n",
        "    cursor.execute(sql_select_query)\n",
        "    data = cursor.fetchall()\n",
        "\n",
        "    cursor.execute(date_select_query)\n",
        "    date = cursor.fetchall()\n",
        "\n",
        "    myconn.close()\n",
        "    return data,date[0][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hZxJwAVjB_w"
      },
      "outputs": [],
      "source": [
        "triplet_id = \"t51\"\n",
        "data, date_value = loadData(triplet_id)\n",
        "print(\"Data:\")\n",
        "for row in data:\n",
        "    print(row)\n",
        "\n",
        "print(\"Date:\", date_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQaXS7QSp_Is",
        "outputId": "f1ceb569-2104-458a-87b5-49f2de6ee2b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[12.7, 33.0, 1054.16, 0.0, 9.17, -0.78, 0.01, -0.39, 6.65, 5.49, 3.84, 0.0, 706.0]\n",
            "[11.9, 20.0, 1054.17, 0.0, 8.33, -0.78, 0.01, -0.39, 6.89, 5.37, 3.84, 0.0, 706.0]\n",
            "[12.2, 29.0, 1054.25, 0.0, 8.33, -0.78, 0.0, -0.4, 6.52, 4.45, 2.38, 0.0, 705.0]\n",
            "[12.1, 21.0, 1054.28, 0.0, 8.33, -0.78, 0.01, -0.4, 7.01, 5.73, 3.6, 0.0, 705.0]\n",
            "[12.1, 31.0, 1054.43, 0.0, 7.5, -0.78, 0.01, -0.39, 6.52, 4.76, 3.35, 0.0, 704.0]\n",
            "[9.9, 25.0, 1054.71, 0.0, 0.83, -0.77, 0.0, -0.41, 6.71, 5.49, 2.38, 0.0, 705.0]\n",
            "[9.6, 26.0, 1054.8, 0.0, 0.83, -0.77, -0.0, -0.41, 6.28, 5.79, 1.34, 0.0, 704.0]\n",
            "[25.5, 25.0, 1054.81, 0.0, 0.0, -0.77, 0.01, -0.42, 7.68, 5.24, 0.61, 0.0, 704.0]\n",
            "[8.9, 28.0, 1054.96, 0.0, 0.0, -0.77, 0.0, -0.42, 7.07, 6.1, -0.12, 0.0, 703.0]\n",
            "[8.4, 29.0, 1055.15, 0.0, 0.0, -0.77, 0.01, -0.43, 7.13, 5.49, -0.85, 0.0, 702.0]\n"
          ]
        }
      ],
      "source": [
        "def dataPreprocess(data):\n",
        "    result = []\n",
        "    data.reverse()\n",
        "\n",
        "    combined_data = []\n",
        "    for i in range(0, len(data), 7):\n",
        "        row = data[i:i+7]\n",
        "        sensor_data = []\n",
        "\n",
        "        for s, d in row:\n",
        "            sid = s\n",
        "            if sid == 's6':\n",
        "                continue\n",
        "            elif sid == 's5':\n",
        "                x = d.split(',')[:6]\n",
        "                for j in x:\n",
        "                    sensor_data.append(float(j))\n",
        "                x = d.split(',')[-1]\n",
        "                sensor_data.append(float(x))\n",
        "            elif sid.startswith('s'):\n",
        "                x = d.split(',')[:]\n",
        "                for j in x:\n",
        "                    sensor_data.append(float(j))\n",
        "\n",
        "        combined_data.extend(sensor_data)\n",
        "\n",
        "    data = np.array(combined_data)\n",
        "    return combined_data\n",
        "\n",
        "\n",
        "preprocessed_data = dataPreprocess(data)\n",
        "split_rows = [preprocessed_data[i:i+13] for i in range(0, len(preprocessed_data), 13)]\n",
        "\n",
        "for row in split_rows:\n",
        "    print(row)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oItTz886p_N9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "data_list = []\n",
        "count = 0\n",
        "for i in range(10):\n",
        "    d = preprocessed_data[count:count+13]\n",
        "    data_list.append(d)\n",
        "    count += 13\n",
        "\n",
        "data_array = np.array(data_list)\n",
        "data_array = data_array.reshape((-1, 10, 13))\n",
        "data_tensor = tf.convert_to_tensor(data_array, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEZZQNM3g5Fg"
      },
      "outputs": [],
      "source": [
        "# Load the first model\n",
        "STOREDIR = ('/content/drive/MyDrive/Count_data-LMS/urni dhank/Encoder_model/finalmodel/')\n",
        "model1 = tf.saved_model.load(STOREDIR)\n",
        "predict_fn = model1.signatures[\"serving_default\"]\n",
        "\n",
        "# Load the second model\n",
        "STOR = \"/content/drive/MyDrive/Count_data-LMS/urni dhank/\"\n",
        "model2 = tf.keras.models.load_model(STOR+'Encoder_model/website1.h5')\n",
        "\n",
        "def runModel(data_tensor):\n",
        "    previous = 1\n",
        "    try:\n",
        "        # Run the prediction on the first model\n",
        "        pred = predict_fn(data_tensor)\n",
        "        pred = np.argmax(pred)\n",
        "        pred = np.round(pred).astype(int)\n",
        "\n",
        "        # Run the prediction on the second model\n",
        "        dt = data_tensor[:,:,0:5]\n",
        "        pred1 = model2.predict(dt)\n",
        "\n",
        "        combined_list = []\n",
        "        combined_list.extend([round(x,2) for x in pred1.tolist()[0]])\n",
        "        combined_list.append(pred)\n",
        "\n",
        "        return (combined_list)\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2BS4hwbvxx0"
      },
      "outputs": [],
      "source": [
        "def insertDatabase(prediction, triplet_id):\n",
        "    connection = mysql.connector.connect(host = \"82.180.142.51\",\n",
        "                                database = \"u978805288_land\",\n",
        "                                user =   \"u978805288_root\",\n",
        "                                password= \"ACSL@b123\")\n",
        "    try:\n",
        "        (connection)\n",
        "        current_time = date+ datetime.timedelta()\n",
        "        print('current_time:',current_time)\n",
        "\n",
        "        val = \"(NULL,'\" +(triplet_id)+\"',\"+ str(prediction[0])+\",\"+ str(prediction[1])+\",\"+str(prediction[2])+\",\"+str(prediction[3])+\",\"+str(prediction[4])+\",\"+str(prediction[5])+ \",'\"+str(current_time)+ \"','no')\"\n",
        "\n",
        "        add_prediction = \"INSERT INTO Prediction_Real_Data  VALUES \"+val\n",
        "        print(add_prediction)\n",
        "\n",
        "        cursor = connection.cursor()\n",
        "        cursor.execute(add_prediction)\n",
        "        connection.commit()\n",
        "        print(cursor.rowcount, \"Record inserted successfully into prediction table\")\n",
        "        cursor.close()\n",
        "\n",
        "    except mysql.connector.Error as error:\n",
        "        print(\"Failed to insert record into prediction table {}\".format(error))\n",
        "\n",
        "    finally:\n",
        "        if connection.is_connected():\n",
        "            connection.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPiCivSW7Bw7"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "  count = 0\n",
        "  for triplet_id in station:\n",
        "    data,date = loadData(triplet_id)\n",
        "    print(date)\n",
        "    date = date+ datetime.timedelta(minutes=10)\n",
        "    data = dataPreprocess(data)\n",
        "    data_list = []\n",
        "    count = 0\n",
        "    for i in range(10):\n",
        "        d = preprocessed_data[count:count+13]\n",
        "        data_list.append(d)\n",
        "        count += 13\n",
        "\n",
        "    data_array = np.array(data_list)\n",
        "    data_array = data_array.reshape((-1, 10, 13))\n",
        "    data_tensor = tf.convert_to_tensor(data_array, dtype=tf.float32)\n",
        "    prediction = runModel(data_tensor)\n",
        "    print(prediction)\n",
        "    insertDatabase(prediction,triplet_id)\n",
        "    print('Enjoy')\n",
        "  count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edIfZm8shTd4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vObrxqIXhThW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TF-Vjpovx4s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeQwQQS98lpy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}