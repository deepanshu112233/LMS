{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IDpn7hA0vxqh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\deepa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tensorflow.keras.models import load_model\n",
        "from multiprocessing import cpu_count\n",
        "from warnings import catch_warnings\n",
        "from warnings import filterwarnings\n",
        "from pandas import read_csv\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas import DataFrame\n",
        "import time\n",
        "#from datetime import datetime\n",
        "import datetime\n",
        "import itertools\n",
        "import mysql.connector\n",
        "from mysql.connector import connection\n",
        "from mysql.connector import errorcode\n",
        "from statistics import mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iUj-dJTOwa2l"
      },
      "outputs": [],
      "source": [
        "station = [\"t39\",\"t56\",\"t61\",\"t72\",\"t79\",\"t101\",\"t103\"]\n",
        "# ,\"t76\",\"t78\",\"t80\"\n",
        "\n",
        "\n",
        "previous_id = np.zeros(len(station))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hFH57JZowa5J"
      },
      "outputs": [],
      "source": [
        "def loadData(t):\n",
        "    myconn = mysql.connector.connect(host = \"82.180.142.51\",\n",
        "                                database = \"u978805288_land\",\n",
        "                                user = \"u978805288_root\",\n",
        "                                password= \"ACSL@b123\")\n",
        "    (myconn)\n",
        "\n",
        "    sql_select_query = \"select sensor_id, value from data_log, info_time where data_log.info_id = info_time.info_id AND data_log.triplet_id = '\"+t+\"' ORDER BY data_log.info_id desc limit 70\"\n",
        "    date_select_query = \"select Date_Time from info_time where triplet_id='\"+t+\"' order by info_id desc limit 1\"\n",
        "\n",
        "    cursor = myconn.cursor()\n",
        "    cursor.execute(sql_select_query)\n",
        "    data = cursor.fetchall()\n",
        "\n",
        "    cursor.execute(date_select_query)\n",
        "    date = cursor.fetchall()\n",
        "\n",
        "    myconn.close()\n",
        "    return data,date[0][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4hZxJwAVjB_w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data:\n",
            "('s7', '205')\n",
            "('s6', '0.00')\n",
            "('s5', '-0.00,-0.00,-0.00,-0.06,-0.06,-0.06,0.00,0.00,0.00,0')\n",
            "('s4', '-2.00')\n",
            "('s3', '0')\n",
            "('s2', '0.00')\n",
            "('s1', '0.00,0')\n",
            "('s7', '180')\n",
            "('s6', '0.00')\n",
            "('s5', '-0.00,-0.00,-0.00,-0.06,-0.06,-0.06,0.00,0.00,0.00,0')\n",
            "('s4', '-2.00')\n",
            "('s3', '0')\n",
            "('s2', '0.00')\n",
            "('s1', '0.00,0')\n",
            "('s7', '195')\n",
            "('s6', '0.00')\n",
            "('s5', '-0.00,-0.00,-0.00,-0.06,-0.06,-0.06,0.00,0.00,0.00,0')\n",
            "('s4', '-2.00')\n",
            "('s3', '0')\n",
            "('s2', '0.00')\n",
            "('s1', '0.00,0')\n",
            "('s7', '203')\n",
            "('s6', '0.00')\n",
            "('s5', '-0.00,-0.00,-0.00,-0.06,-0.06,-0.06,0.00,0.00,0.00,0')\n",
            "('s4', '-2.00')\n",
            "('s3', '0')\n",
            "('s2', '0.00')\n",
            "('s1', '0.00,0')\n",
            "('s7', '118')\n",
            "('s6', '0.00')\n",
            "('s5', '-0.00,-0.00,-0.00,-0.06,-0.06,-0.06,0.00,0.00,0.00,0')\n",
            "('s4', '-2.00')\n",
            "('s3', '0')\n",
            "('s2', '0.00')\n",
            "('s1', '0.00,0')\n",
            "('s7', '145')\n",
            "('s6', '0.00')\n",
            "('s5', '-0.00,-0.00,-0.00,-0.06,-0.06,-0.06,0.00,0.00,0.00,0')\n",
            "('s4', '-2.00')\n",
            "('s3', '0')\n",
            "('s2', '0.00')\n",
            "('s1', '0.00,0')\n",
            "('s7', '164')\n",
            "('s6', '0.00')\n",
            "('s5', '-0.00,-0.00,-0.00,-0.06,-0.06,-0.06,0.00,0.00,0.00,0')\n",
            "('s4', '-2.00')\n",
            "('s3', '0')\n",
            "('s2', '0.00')\n",
            "('s1', '0.00,0')\n",
            "('s7', '237')\n",
            "('s6', '0.00')\n",
            "('s5', '-0.00,-0.00,-0.00,-0.06,-0.06,-0.06,0.00,0.00,0.00,0')\n",
            "('s4', '-2.00')\n",
            "('s3', '0')\n",
            "('s2', '0.00')\n",
            "('s1', '0.00,0')\n",
            "('s7', '137')\n",
            "('s6', '0.00')\n",
            "('s5', '-0.00,-0.00,-0.00,-0.06,-0.06,-0.06,0.00,0.00,0.00,0')\n",
            "('s4', '-2.00')\n",
            "('s3', '0')\n",
            "('s2', '0.00')\n",
            "('s1', '0.00,0')\n",
            "('s7', '152')\n",
            "('s6', '0.00')\n",
            "('s5', '-0.00,-0.00,-0.00,-0.06,-0.06,-0.06,0.00,0.00,0.00,0')\n",
            "('s4', '-2.00')\n",
            "('s3', '0')\n",
            "('s2', '0.00')\n",
            "('s1', '0.00,0')\n",
            "Date: 2024-06-07 22:18:22\n",
            "70\n"
          ]
        }
      ],
      "source": [
        "triplet_id = \"t56\"\n",
        "data, date_value = loadData(triplet_id)\n",
        "print(\"Data:\")\n",
        "for row in data:\n",
        "    print(row)\n",
        "\n",
        "print(\"Date:\", date_value)\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "station=[\"t56\"]\n",
        "# station = [\"t39\", \"t56\", \"t61\", \"t72\", \"t79\", \"t101\", \"t103\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID: t56 len:  130\n",
            "[0.0, 0.0, 0.0, 0.0, -2.0, -0.0, -0.0, -0.0, -0.06, -0.06, -0.06, 0.0, 152.0]\n",
            "[0.0, 0.0, 0.0, 0.0, -2.0, -0.0, -0.0, -0.0, -0.06, -0.06, -0.06, 0.0, 137.0]\n",
            "[0.0, 0.0, 0.0, 0.0, -2.0, -0.0, -0.0, -0.0, -0.06, -0.06, -0.06, 0.0, 237.0]\n",
            "[0.0, 0.0, 0.0, 0.0, -2.0, -0.0, -0.0, -0.0, -0.06, -0.06, -0.06, 0.0, 164.0]\n",
            "[0.0, 0.0, 0.0, 0.0, -2.0, -0.0, -0.0, -0.0, -0.06, -0.06, -0.06, 0.0, 145.0]\n",
            "[0.0, 0.0, 0.0, 0.0, -2.0, -0.0, -0.0, -0.0, -0.06, -0.06, -0.06, 0.0, 118.0]\n",
            "[0.0, 0.0, 0.0, 0.0, -2.0, -0.0, -0.0, -0.0, -0.06, -0.06, -0.06, 0.0, 203.0]\n",
            "[0.0, 0.0, 0.0, 0.0, -2.0, -0.0, -0.0, -0.0, -0.06, -0.06, -0.06, 0.0, 195.0]\n",
            "[0.0, 0.0, 0.0, 0.0, -2.0, -0.0, -0.0, -0.0, -0.06, -0.06, -0.06, 0.0, 180.0]\n",
            "[0.0, 0.0, 0.0, 0.0, -2.0, -0.0, -0.0, -0.0, -0.06, -0.06, -0.06, 0.0, 205.0]\n"
          ]
        }
      ],
      "source": [
        "def dataPreprocess(data):\n",
        "    result = []\n",
        "    data.reverse()\n",
        "\n",
        "    combined_data = []\n",
        "    for i in range(0, len(data), 7):\n",
        "        row = data[i:i+7]\n",
        "        sensor_data = []\n",
        "        for s, d in row:\n",
        "            # print(\"R: \",row)\n",
        "            sid = s\n",
        "            if sid == 's6':\n",
        "                continue\n",
        "            elif sid == 's5':\n",
        "                x = d.split(',')[:6]\n",
        "                for j in x:\n",
        "                    sensor_data.append(float(j))\n",
        "                x = d.split(',')[-1]\n",
        "                sensor_data.append(float(x))\n",
        "            elif sid.startswith('s') and sid != 's5':\n",
        "                x = d.split(',')[:]\n",
        "                for j in x:\n",
        "                    sensor_data.append(float(j))\n",
        "\n",
        "        combined_data.extend(sensor_data)\n",
        "\n",
        "    data = np.array(combined_data)\n",
        "    return combined_data\n",
        "\n",
        "\n",
        "for id in station:\n",
        "    data, date_value = loadData(id)\n",
        "    preprocessed_data = dataPreprocess(data)\n",
        "    split_rows = [preprocessed_data[i:i+13]\n",
        "                  for i in range(0, len(preprocessed_data), 13)]\n",
        "    print(\"ID:\", id, \"len: \", len(preprocessed_data))\n",
        "    for row in split_rows:\n",
        "        print(row)\n",
        "# Temp   Humi    Press   Rain    Light   Ax,Ay,Az,Wx,Wy,Wz   Moisture\n",
        "#API: t56\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQaXS7QSp_Is",
        "outputId": "f1ceb569-2104-458a-87b5-49f2de6ee2b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID: t103 l:  130\n",
            "[37.2, 26.0, 1042.5, 0.0, 4055.0, -0.96, 0.06, -0.12, 14.7, 10.0, 4.45, 0.0, 232.0]\n",
            "[37.6, 26.0, 1042.38, 0.0, 4057.5, -0.96, 0.06, -0.12, 12.13, 9.02, 6.59, 0.0, 234.0]\n",
            "[37.1, 26.0, 1042.14, 0.0, 4147.5, -0.97, 0.05, -0.13, 13.35, 8.23, 6.52, 0.0, 234.0]\n",
            "[37.8, 25.0, 1042.06, 0.0, 4190.0, -0.97, 0.05, -0.12, 14.88, 8.72, 5.91, 0.0, 237.0]\n",
            "[38.4, 26.0, 1041.86, 0.0, 4166.67, -0.97, 0.05, -0.13, 14.39, 9.09, 7.62, 0.0, 236.0]\n",
            "[38.8, 25.0, 1041.68, 0.0, 4360.0, -0.96, 0.05, -0.12, 13.72, 12.99, 5.0, 0.0, 237.0]\n",
            "[38.6, 25.0, 1041.53, 0.0, 4013.33, -0.96, 0.05, -0.13, 12.99, 9.27, 7.01, 0.0, 233.0]\n",
            "[38.9, 25.0, 1041.28, 0.0, 4361.67, -0.96, 0.05, -0.13, 12.26, 9.76, 5.98, 0.0, 237.0]\n",
            "[38.5, 24.0, 1041.21, 0.0, 4351.67, -0.96, 0.06, -0.12, 16.1, 8.54, 5.18, 0.0, 236.0]\n",
            "[39.2, 23.0, 1041.16, 0.0, 4103.33, -0.97, 0.06, -0.13, 13.72, 9.15, 3.23, 0.0, 236.0]\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oItTz886p_N9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "data_list = []\n",
        "count = 0\n",
        "for i in range(10):\n",
        "    d = preprocessed_data[count:count+13]\n",
        "    data_list.append(d)\n",
        "    count += 13\n",
        "\n",
        "data_array = np.array(data_list)\n",
        "data_array = data_array.reshape((-1, 10, 13))\n",
        "data_tensor = tf.convert_to_tensor(data_array, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEZZQNM3g5Fg"
      },
      "outputs": [],
      "source": [
        "# Load the first model\n",
        "STOREDIR = ('/content/drive/MyDrive/Count_data-LMS/urni dhank/Encoder_model/finalmodel/')\n",
        "model1 = tf.saved_model.load(STOREDIR)\n",
        "predict_fn = model1.signatures[\"serving_default\"]\n",
        "\n",
        "# Load the second model\n",
        "STOR = \"/content/drive/MyDrive/Count_data-LMS/urni dhank/\"\n",
        "model2 = tf.keras.models.load_model(STOR+'Encoder_model/website1.h5')\n",
        "\n",
        "def runModel(data_tensor):\n",
        "    previous = 1\n",
        "    try:\n",
        "        # Run the prediction on the first model\n",
        "        pred = predict_fn(data_tensor)\n",
        "        pred = np.argmax(pred)\n",
        "        pred = np.round(pred).astype(int)\n",
        "\n",
        "        # Run the prediction on the second model\n",
        "        dt = data_tensor[:,:,0:5]\n",
        "        pred1 = model2.predict(dt)\n",
        "\n",
        "        combined_list = []\n",
        "        combined_list.extend([round(x,2) for x in pred1.tolist()[0]])\n",
        "        combined_list.append(pred)\n",
        "\n",
        "        return (combined_list)\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2BS4hwbvxx0"
      },
      "outputs": [],
      "source": [
        "def insertDatabase(prediction, triplet_id):\n",
        "    connection = mysql.connector.connect(host = \"82.180.142.51\",\n",
        "                                database = \"u978805288_land\",\n",
        "                                user =   \"u978805288_root\",\n",
        "                                password= \"ACSL@b123\")\n",
        "    try:\n",
        "        (connection)\n",
        "        current_time = date+ datetime.timedelta()\n",
        "        print('current_time:',current_time)\n",
        "\n",
        "        val = \"(NULL,'\" +(triplet_id)+\"',\"+ str(prediction[0])+\",\"+ str(prediction[1])+\",\"+str(prediction[2])+\",\"+str(prediction[3])+\",\"+str(prediction[4])+\",\"+str(prediction[5])+ \",'\"+str(current_time)+ \"','no')\"\n",
        "\n",
        "        add_prediction = \"INSERT INTO Prediction_Real_Data  VALUES \"+val\n",
        "        print(add_prediction)\n",
        "\n",
        "        cursor = connection.cursor()\n",
        "        cursor.execute(add_prediction)\n",
        "        connection.commit()\n",
        "        print(cursor.rowcount, \"Record inserted successfully into prediction table\")\n",
        "        cursor.close()\n",
        "\n",
        "    except mysql.connector.Error as error:\n",
        "        print(\"Failed to insert record into prediction table {}\".format(error))\n",
        "\n",
        "    finally:\n",
        "        if connection.is_connected():\n",
        "            connection.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPiCivSW7Bw7"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "  count = 0\n",
        "  for triplet_id in station:\n",
        "    data,date = loadData(triplet_id)\n",
        "    print(date)\n",
        "    date = date+ datetime.timedelta(minutes=10)\n",
        "    data = dataPreprocess(data)\n",
        "    data_list = []\n",
        "    count = 0\n",
        "    for i in range(10):\n",
        "        d = preprocessed_data[count:count+13]\n",
        "        data_list.append(d)\n",
        "        count += 13\n",
        "\n",
        "    data_array = np.array(data_list)\n",
        "    data_array = data_array.reshape((-1, 10, 13))\n",
        "    data_tensor = tf.convert_to_tensor(data_array, dtype=tf.float32)\n",
        "    prediction = runModel(data_tensor)\n",
        "    print(prediction)\n",
        "    insertDatabase(prediction,triplet_id)\n",
        "    print('Enjoy')\n",
        "  count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edIfZm8shTd4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vObrxqIXhThW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TF-Vjpovx4s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeQwQQS98lpy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
